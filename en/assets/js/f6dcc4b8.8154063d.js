"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6045],{6824:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>p,toc:()=>c});var r=t(5893),i=t(1151);const s={sidebar_position:11},o="\u4f7f\u7528 Python3 \u64cd\u4f5c OpenCV",p={id:"TinyVision/part3/UsePython3ToOperateOpenCV",title:"\u4f7f\u7528 Python3 \u64cd\u4f5c OpenCV",description:"\u52fe\u9009 OpenCV-Python3 \u5305",source:"@site/docs/TinyVision/part3/11-UsePython3ToOperateOpenCV.md",sourceDirName:"TinyVision/part3",slug:"/TinyVision/part3/UsePython3ToOperateOpenCV",permalink:"/en/docs/TinyVision/part3/UsePython3ToOperateOpenCV",draft:!1,unlisted:!1,editUrl:"https://github.com/100askTeam/linuxboard-docs/tree/main/docs/TinyVision/part3/11-UsePython3ToOperateOpenCV.md",tags:[],version:"current",sidebarPosition:11,frontMatter:{sidebar_position:11},sidebar:"v851seSidebar",previous:{title:"\u4f7f\u7528 OpenCV \u6355\u83b7\u6444\u50cf\u5934\u5e76\u4e14\u8f93\u51fa\u5230\u5c4f\u5e55\u4e0a",permalink:"/en/docs/TinyVision/part3/UseOpenCVToCaptureTheCameraAndDisplayItOnTheScreen"},next:{title:"\u7f16\u8bd1\u7cfb\u7edf",permalink:"/en/docs/TinyVision/part3/BuildTheSystem"}},a={},c=[{value:"\u52fe\u9009 OpenCV-Python3 \u5305",id:"\u52fe\u9009-opencv-python3-\u5305",level:3}];function f(e){const n={code:"code",h1:"h1",h3:"h3",img:"img",p:"p",pre:"pre",...(0,i.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"\u4f7f\u7528-python3-\u64cd\u4f5c-opencv",children:"\u4f7f\u7528 Python3 \u64cd\u4f5c OpenCV"}),"\n",(0,r.jsx)(n.h3,{id:"\u52fe\u9009-opencv-python3-\u5305",children:"\u52fe\u9009 OpenCV-Python3 \u5305"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"m menuconfig"})," \u8fdb\u5165\u8f6f\u4ef6\u5305\u914d\u7f6e\uff0c\u52fe\u9009"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"OpenCV  ---\x3e\n\t<*> opencv....................................................... opencv libs\n\t[*]   Enabel sunxi vin isp support\n\t[*]   Enabel opencv python3 binding support\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"image-20240122202827423",src:t(4200).Z+"",width:"1129",height:"635"})}),"\n",(0,r.jsx)(n.p,{children:"\u7136\u540e\u7f16\u8bd1\u56fa\u4ef6\u5373\u53ef\uff0c\u8bf7\u6ce8\u610f Python3 \u7f16\u8bd1\u975e\u5e38\u6162\uff0c\u800c\u4e14\u9700\u8981\u7f16\u8bd1\u673a\u670916G\u4ee5\u4e0a\u5185\u5b58\uff0c\u9700\u8981\u8010\u5fc3\u7b49\u5f85\u4e0b\u3002"}),"\n",(0,r.jsx)(n.p,{children:"\u7f16\u5199\u4e00\u4e2a Python \u811a\u672c\uff0c\u6267\u884c\u4e0a\u9762\u7684\u76f8\u540c\u64cd\u4f5c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\n\nDISPLAY_X = 240\nDISPLAY_Y = 240\n\nframe_width = 480\nframe_height = 480\nframe_rate = 30\n\ncap = cv2.VideoCapture(0) # \u6253\u5f00\u6444\u50cf\u5934\n\nif not cap.isOpened():\n    print("Could not open video device.")\n    exit(1)\n\nprint("Successfully opened video device.")\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\ncap.set(cv2.CAP_PROP_FPS, frame_rate)\n\nofs = open("/dev/fb0", "wb") # \u6253\u5f00\u5e27\u7f13\u51b2\u533a\n\nwhile True:\n    ret, frame = cap.read() # \u8bfb\u53d6\u4e00\u5e27\u56fe\u50cf\n    if frame.dtype != np.uint8 or frame.ndim != 3:\n        print("Not 8 bits per pixel and channel.")\n    elif frame.shape[2] != 3:\n        print("Not 3 channels.")\n    else:\n        frame = cv2.transpose(frame) # \u56fe\u50cf\u8f6c\u7f6e\n        frame = cv2.flip(frame, 0) # \u56fe\u50cf\u7ffb\u8f6c\n        frame = cv2.resize(frame, (DISPLAY_X, DISPLAY_Y)) # \u6539\u53d8\u56fe\u50cf\u5927\u5c0f\n        framebuffer_width = DISPLAY_X\n\t\t_ = open("/sys/class/graphics/fb0/bits_per_pixel", "r")\n\t\tframebuffer_depth = int(_.read()[:2])\n\t\t_.close()\n        frame_size = frame.shape\n        framebuffer_compat = np.zeros(frame_size, dtype=np.uint8)\n        if framebuffer_depth == 16:\n            framebuffer_compat = cv2.cvtColor(frame, cv2.COLOR_BGR2BGR565)\n            for y in range(frame_size[0]):\n                ofs.seek(y * framebuffer_width * 2)\n                ofs.write(framebuffer_compat[y].tobytes())\n        elif framebuffer_depth == 32:\n            split_bgr = cv2.split(frame)\n            split_bgr.append(np.full((frame_size[0], frame_size[1]), 255, dtype=np.uint8))\n            framebuffer_compat = cv2.merge(split_bgr)\n            for y in range(frame_size[0]):\n                ofs.seek(y * framebuffer_width * 4)\n                ofs.write(framebuffer_compat[y].tobytes())\n        else:\n            print("Unsupported depth of framebuffer.")\n\ncap.release()\nofs.close()\n\n'})})]})}function d(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(f,{...e})}):f(e)}},4200:(e,n,t)=>{t.d(n,{Z:()=>r});const r=t.p+"assets/images/image-20240122202827423-7d4c69c44c67d6b7c190ef99d8645a41.png"},1151:(e,n,t)=>{t.d(n,{Z:()=>p,a:()=>o});var r=t(7294);const i={},s=r.createContext(i);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function p(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);